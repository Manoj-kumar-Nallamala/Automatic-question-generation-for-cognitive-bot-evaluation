Extraction phase
######################################################################################################
import nltk
from nltk import word_tokenize,pos_tag,sent_tokenize


def remove_appos(tokens_tag,text):#function to remove appositive(',') and elminating the relative pronouns
  index_of_appos=None
  for i in range(0,len(tokens_tag)-1):
      if tokens_tag[i][1]=='NNP' and tokens_tag[i+1][0]==',':#finding if appositive (',')present after noun phrase
        index_of_appos=i+1
        break
  if index_of_appos!=None:
     text[index_of_appos]='is'#eliminating appositive(',')
     wrb_flag=0#presence of relative adverb
     if tokens_tag[index_of_appos+1][1]=='WP' or tokens_tag[index_of_appos+1][1]=='WRB':
        if tokens_tag[index_of_appos+1][1]=='WRB':
           wrb_flag=1
        del text[index_of_appos+1]#removing relative pronoun for nouns('who')
        del text[index_of_appos]
        if wrb_flag==1:#removing relative pronoun for nouns('where')
          new=text[:]
          new=new[index_of_appos:]
          new.append('in')
          new.append(text[0])
          text=new[:]
  return text



def remove_modifiers(text):
  #removing non restrictive appositive (,) after the subject
  text=word_tokenize(text)
  tokens_tag = pos_tag(text)
  text=remove_appos(tokens_tag,text)
  print(text)


def main():
   str0="Hyderabad,where the charminar is located"
   str1="Jeff,the president of USA"
   str2="Jeff,who was the president of USA"
   modified_sentence=remove_modifiers(str0)
   modified_sentence=remove_modifiers(str1)
   modified_sentence=remove_modifiers(str2)
   print(modified_sentence)

if __name__ == '__main__':
    main()
##############################################################################################
Yes or no question generation
##############################################################################################
#importing libraries
import nltk
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
from nltk import word_tokenize,pos_tag,sent_tokenize

helping_verbs=['am','is','are','was','were','being','been','be',
'have','has','had','do','does','did','will','would','shall','should','may','might','must','can','could']

main_verb_tags=['VBG','VB','VBD','VBZ','VBP']

nn_prp_tags=['NN','NNP','PRP',',','DT']

third_person_singular=['He','She','It']

def reconstruct(list):     #reconstructing list to sentence
   list[0]=list[0].title()
   list.append('?')        #adding question mark to the question 
   str1 = ' '.join(list)
   return str1

def yes_or_no_ques(text,tokens_tag):  #function for generating questions with boolean values as answers
   hv_flag=None
   new=[]
   if tokens_tag[0][1]=='PRP':
      text[0]=text[0].lower()    ## corrected only when pronoun is at the begining
   for i in range(0,len(tokens_tag)):    #loop for identifying helping verb
      if tokens_tag[i][0] in helping_verbs:
         hv_flag=i
         break
   if hv_flag!=None:    #framing question with a helping verb in sentence 
#      if text[hv_flag] in helping_verbs[14:]:
#         text[hv_flag]=text[hv_flag]+"n't"
      new.append(text[hv_flag])
      del text[hv_flag]
      for i in range(0,len(text)):
         new.append(text[i])
      return reconstruct(new)
   else:           #framing question with out helping verb
      do_form=None
      main_verb=None
      subject=text[0]
      for i in range(0,len(tokens_tag)):  #loop for finding main verb
         if tokens_tag[i][1] in main_verb_tags:
            do_form=tokens_tag[i][1]  #identifying the tense of main verb
            main_verb=i
            break
      if do_form=='VBD':    #identifying appropriate do-form of the verb
         do_form='Did'      #do-form for past tense
      elif do_form=='VB':
         if subject in third_person_singular:      #do form for plural present tense form of the verb

           do_form='Does'
      else:                 #do form for singular present tense of the verb
         do_form='Do'
      new.append(do_form)
      text[main_verb]=lemmatizer.lemmatize(text[main_verb], pos='v')#obtaining main form of the verb
      for i in range(0,len(text)):
         new.append(text[i])
      return reconstruct(new)

def identify_subject(text,tokens_tag):   ##identifies the subject
   for i in range(0,len(tokens_tag)):
      if tokens_tag[i][1] in nn_prp_tags and tokens_tag[i+1][1] not in nn_prp_tags:   #subject can be noun or a pronoun
         sub=i
         break
   remain=yes_or_no_ques(text[i:],tokens_tag[i:])       #we will use the next part of sentence for generating question
   return remain

def main():
   text=input("Enter sentence : ")
   text=sent_tokenize(text)

   for i in range(0,len(text)):
     print(text[i])
     text1=word_tokenize(text[i])     #word-tokenzing
     tokens_tag=pos_tag(text1)     #pos-tagging
     str=identify_subject(text1,tokens_tag)
     print(str)
if __name__ == '__main__':
  main()
#################################################################################################
wh_ques
##############################################################################################
#importing libraries
import nltk
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
from nltk import word_tokenize,pos_tag,sent_tokenize
import spacy
import en_core_web_sm
nlp = en_core_web_sm.load()

helping_verbs=['am','is','are','was','were','being','been','be',
'have','has','had','do','does','did','will','would','shall','should','may','might','must','can','could']

main_verb_tags=['VBG','VB','VBD','VBZ','VBP']

nn_prp_tags=['NN','NNP','PRP',',','DT']

third_person_singular=['He','She','It']

wh_map={'PERSON':'Who','LOC':'Where','ORG':'Which','DATE':'When','TIME':'When','MONEY':'How much'}

entities=['PERSON','LOC','ORG','DATE','TIME','MONEY']

def reconstruct(list,tokens_tag):     #reconstructing list to sentence
   list[0]=list[0].title()
   if tokens_tag[-1][1]=='IN':
           del list[-1]

   list.append('?')        #adding question mark to the question 
   str1 = ' '.join(list)
   return str1

def yes_or_no_ques(text,tokens_tag):  #function for generating questions with boolean values as answers
   hv_flag=None
   new=[]
   if tokens_tag[0][1]=='PRP':
      text[0]=text[0].lower()    ## corrected only when pronoun is at the begining
   for i in range(0,len(tokens_tag)):    #loop for identifying helping verb
      if tokens_tag[i][0] in helping_verbs:
         hv_flag=i
         break
   if hv_flag!=None:    #framing question with a helping verb in sentence 
#      if text[hv_flag] in helping_verbs[14:]:
#         text[hv_flag]=text[hv_flag]+"n't"
      new.append(text[hv_flag])
      del text[hv_flag]
      for i in range(0,len(text)):
         new.append(text[i])
      return reconstruct(new,tokens_tag)
   else:           #framing question with out helping verb
      do_form=None
      main_verb=None
      subject=text[0]
      for i in range(0,len(tokens_tag)):  #loop for finding main verb
         if tokens_tag[i][1] in main_verb_tags:
            do_form=tokens_tag[i][1]  #identifying the tense of main verb
            main_verb=i
            break
      if do_form=='VBD':    #identifying appropriate do-form of the verb
         do_form='Did'      #do-form for past tense
      elif do_form=='VB':
         if subject in third_person_singular:      #do form for plural present tense form of the verb

           do_form='Does'
      else:                 #do form for singular present tense of the verb
         do_form='Do'
      new.append(do_form)
      text[main_verb]=lemmatizer.lemmatize(text[main_verb], pos='v')#obtaining main form of the verb
      for i in range(0,len(text)):
         new.append(text[i])
      return reconstruct(new,tokens_tag)

def identify_subject(text,tokens_tag):   ##identifies the subject
   for i in range(0,len(tokens_tag)):
      if tokens_tag[i][1] in nn_prp_tags and tokens_tag[i+1][1] not in nn_prp_tags:   #subject can be noun or a pronoun
         sub = i
         break
   remain=yes_or_no_ques(text[i:],tokens_tag[i:])       #we will use the next part of sentence for generating question
   return remain


def decompose(text,tokens_tag,ent_type):   ##function identifies each entity with it's corresponding Question word.
   print(identify_subject(text,tokens_tag))   ##Genenrating yes_or_no questions.
   for i in range(0,len(ent_type)):           ##Loop for generating questions on all possible entity types.
      temp=text[:]
      if ent_type[i][1] not in entities:   ##if entity is not recognized as a known entity
          continue
      if i == 0 :
          temp[i] = wh_map[ent_type[i][1]]      ##If entity is present in the subject of a sentence.
          print(reconstruct(temp,tokens_tag))

      elif ent_type[i][1] == 'PERSON':         ##If entity is present in the object of a sentence.
          place = text.index(ent_type[i][1])
          del temp[place]
          str = identify_subject(temp,tokens_tag)
          str = 'Whom'+" "+str.lower()
          print(str)
      else:
          place=text.index(ent_type[i][0])
          del temp[place]
          del tokens_tag[place]
          str = identify_subject(temp,tokens_tag)
          str = wh_map[ent_type[i][1]]+" "+str.lower()
          print(str)
def main():
     file = open(“sample.txt”, “r”)     ##Reading input from file
     text = file.read()
     sent = sent_tokenize(text)
     for i in range(0,len(sent)):      ##Generating possible questions from each sentence in the comprehension
         text1 = sent[i]
         text1 = word_tokenize(text1)   ##Tokenization using nltk.
         tokens_tag = pos_tag(text1)
         print(tokens_tag)
         doc = nlp(sent[i])
         ent_type = []
         print(ent_type)
         for X in doc.ents:
            ent_type.append((X.text, X.label_))
            print(ent_type)
         decompose(text1,tokens_tag,ent_type)
if __name__ == '__main__':
  main()
